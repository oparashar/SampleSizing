BACKGROUND:

Hello! This is Captain Ojas Parashar writing to you from Germany. 

I wanted to use some of the skills I've learned in the OMSA (Online Masters of Science in Analytics) to model something that's always puzzled me - why do we use 10% samples? 10% seems like a very arbitrary number and definitely doesn't take into account the actual amount of error occurring in the data set. So I thought I'd analytically figure what the optimal sample size would be for a given error rate. 

While there may be a simple way to analytically derive this, I'll instead be utilizng modeling tools, more than likely a Monte Carlo simulation to figure out what happens if you take an N% sample given a M% error rate assuming A% accuracry of the test. 

More to come later!

CHANGELOG:

13 May 2024 - Initial. Starting code. 
